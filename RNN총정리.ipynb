{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN: trained using the current inputs only, not consider previous inputs when generating the current output which means the system didn't have _memory elements._ <br />\n",
    "RNN: use memory(i.e. past inputs to the network) when producing the current output.<br /><br />\n",
    "Many applications involve temporal dependencies(or dependencies over time) which means our current output depends not only on the current input, but also on past inputs.RNN is artificial neural networks that can capture temporal dependencies.<br />\n",
    "* RECURRENT\n",
    "    : Occuring often or repeatedly\n",
    "* RNN\n",
    "    : Perform the same task for each element in the input sequence<br />\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple History"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the first wave of artificial neural networks in the mid 80s, it became clear that feedforward networks are limited since they are unable to capture temporal dependencies(dependencies that change over time). Modeling temporal data is critical in most real-world applications, since natural signals like speech and video have time varying properties and are characterized by having dependencies across time. By the way, biological neural networks have recurring connections,so applying recurrence to artificial feedforward neural networks made natural sense. The first attempt to add memory to neural networks were the Time Delay Neural Networks(TDNN). And TDNNs, inputs from past timesteps were introduced to the network input, changing the actual external inputs. This had the advantage of clearly allowing the network to look 'beyond' the current timestep, but also introduce to clear disadvantage, since the temporal dependencies were limited to the window of the time chosen. Simple RNNs, also known as Elman networks and Jordan networks were next to follow. It was recognized in the early 90s that all of these networks suffer from what we call, 'vanishing gradient' problem.\n",
    "\n",
    "\n",
    "RNNs have a key flaw, as capturing relationships that span more than 9 or 10 steps back is practically impossible. This flaw stems from the **\"vanishing gradient\"** problem in which the contribution of information decays gemetrically over time. <br />\n",
    "While training network we use **backpropagation**. In the backpropagation process we adjust our weight matrices with the use of a gradient. In the process gradients are calculated by continuous multiplications of derivatives. The value of these derivatives may be so small, that these continuous multiplications may cause the gradient to practically \"vanish\".<br />\n",
    "**LSTM** is the option to overcome the Vanish Gradient problem in RNNs. Gated Recurrent Units(GRUs) also gives a solution to the problem, by helping us apply networks that have temporal dependencies. <br />\n",
    "The key novelty in LSTMs was the idea that some signals, what we call state variables, can be kept fixed by using gates and reintroduced or not at an appropriate time in the future. In this way, arbitrary time intervals can be represented,and temporal dependencies can be captured.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Speech Recognition\n",
    "* Time Series Prediction\n",
    "    + traffic patterns\n",
    "    + movie selection\n",
    "    + stock movement and market conditions\n",
    "* Natural Language Processing\n",
    "    + machine translation\n",
    "    + question answering\n",
    "    + chatbots\n",
    "* Gesture Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feedforward Neural Network - A Reminder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mathematical calculations needed for training RNN systems are fascinating. To deeply understand the process, we first need to feel confident with the **vanilla FFNN system**. We need to thoroughly understand the feedforward process, as well as the backpropagation process used in the training phases of such systems. <br />\n",
    "When working with neural networks we have 2 primary phases:<br />\n",
    "**Training** and **Evaluation**,<br />\n",
    "During the **training** phase, we take the data set (also called the _training set_), which includes many pairs of inputs and their corresponding targets(outputs) -> Supervised Learning Our goal is to find a \"set of weights\" that would best map the inputs to the desired outputs. In the **evaluation** phase, we use the network that was created in the training phase, apply new inputs and expect to obtain the desired output. <br />\n",
    "The training phase will include 2 steps: <br />\n",
    "**Feedfoward** and **Backpropagation** <br />\n",
    "We will repeat these steps as many times as we need until we decide that our system has reached the best set of weights, giving us the best possible outputs.<br />\n",
    "**Goal: To yield a network that generalizes beyond the train set** <br />\n",
    "The output will be compared to the correct output giving us an indication of the error. There are a few ways to determine the error.\n",
    "In the backpropagation part, we will change the weights as we try to minimize the **'error'**, and start the feedforward process all over again."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](https://user-images.githubusercontent.com/46597294/72312737-61303900-36cc-11ea-8ecc-2e2c8e3709ed.png)\n",
    "![image](https://user-images.githubusercontent.com/46597294/72312585-e49d5a80-36cb-11ea-84ad-5ea811b60bf9.png)\n",
    "**Activation function** <br />\n",
    "* Allows the network to represent nonlinear relationships between its inputs and its outputs\n",
    "* Most real world data is nonlinear <br />\n",
    "Using these functions can be a bit tricky as they contribute to the vanishing gradient problem.\n",
    "![image](https://user-images.githubusercontent.com/46597294/72312106-5674a480-36ca-11ea-98ba-eeed36f1824a.png)\n",
    "\n",
    "![image](https://user-images.githubusercontent.com/46597294/72312946-12cf6a00-36cd-11ea-8e41-ad4850cfcee1.png)\n",
    "**Softmax function** <br />\n",
    "We don't need necessarily need an activation function at the output. In some applications, it can be beneficial to use for example, a softmax function, if we want the output values to be between 0 and 1.\n",
    "![image](https://user-images.githubusercontent.com/46597294/72311711-f2051580-36c8-11ea-9138-44f815bed48d.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Error calculations**<br />\n",
    "For our back propagation calculations, we will use the squared error, which is also called 'loss function'.<br />\n",
    "## Simple Backpropagation Theory \n",
    "Backpropagation is essentially stochastic gradient descent computed using the chain rule. <br />\n",
    "**Simple Weight Update** <br />\n",
    "$ \\underset{new}{W} = \\underset{previous}{W} + {\\alpha}({-{\\partial}E \\over {\\partial}W}) $ <br />\n",
    "* ${\\alpha}$ : learning rate\n",
    "* ${-{\\partial}E \\over {\\partial}W}$ : partial derivative <br />\n",
    "\n",
    "Partial derivative lets us measure how the error is impacted by each weight separately<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "As computing the output, we can finally find the network error. As a reminder, the two Error functions most commonly used are the **Mean Squared Error(MSE)**(usually used in regression problems) and the **cross entropy**(often used in classification problems)<br />\n",
    "For example, let's use a variation of the MSE:<br />\n",
    "$E = {(d-y)^2 \\over 2}$ <br />\n",
    "where $d$ is the desired output and $y$ is the calculated one. Notice that **y** and **d** are not vectors if we have a single output.<br />\n",
    "The error is their squared difference. $E = (d-y)^2$, and is also called the network's **loss function.** We are dividing the error term by 2 to simplify notation. <br />\n",
    "**The aim of the backprop process is to minimize the error, which in our case is the _Loss Function_.** <br /><br />\n",
    "The weight update value $\\bigtriangleup W_{ij}^k$ is calculated with the use of the gradient the following way: <br />\n",
    "$ \\bigtriangleup W_{ij}^k = {\\alpha}({-{\\partial}E \\over {\\partial}W}) $ <br />\n",
    "Therefore: <br />\n",
    "$ \\bigtriangleup W_{ij}^k = \\alpha ({-{\\partial}E \\over {\\partial}W}) = -{\\alpha \\over 2} {{\\partial}(d-y)^2 \\over {\\partial}W_{ij}} = -2{\\alpha \\over 2}(d-y){{\\partial}(d-y) \\over {\\partial}W_{ij}}$ <br />\n",
    "which can be simplified as: <br />\n",
    "$\\bigtriangleup W_{ij}^k = \\alpha(d-y){{\\partial}y \\over {\\partial}W_{ij}}$ <br />\n",
    "(Notice that $d$ is a constant value, so it's partial derivative is simply a zero)<br />\n",
    "This partial derivative of the output with respect to each weight, defines the **gradient** and is often denoted by the Greek letter $\\delta$.<br />\n",
    "$\\delta_{ij} = {{\\partial}y \\over {\\partial}W_{ij}}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](https://user-images.githubusercontent.com/46597294/72326672-f6462880-36f2-11ea-8b36-60c41c0fce84.png)\n",
    "![image](https://user-images.githubusercontent.com/46597294/72326746-170e7e00-36f3-11ea-8a28-9f403e059dec.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each new input we updated the weights after each calculation of the output. It is often beneficial _**to update the weights once every N steps**_. This is called **mini batch training** and involves averaging the changes to the weights over multiple steps before actually updating the weights.<br />\n",
    "$\\delta = {1 \\over N}\\sum_{h}^{N} \\delta_{ij}$<br />\n",
    "There are two primary reasons for using mini batch training.\n",
    "* Reduction of the complexity of the training process\n",
    "* Noise reduction<br />\n",
    "\n",
    "Noise reduction is that when we average multiple, possibly noisy changes to the weights,we end up with a less noisy correction. This means that the learning process may actually converge faster and more accurately.<br />\n",
    "\n",
    "What's the difference between Batch Gradient Descent and Stochastic Gradient Descent?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# backprop 에서 error 자체를 MSE로 하네 \n",
    "# GARCH 공부하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overfitting\n",
    "When we minimize the network error using backprop, we may either properly fit the model to the data or overfit. Generally speaking, when we have a finite training set, there's a risk of overfitting.<br />\n",
    "Overfitting means that our model will fit the training data too closely. In other words, we over trained the model or the network to fit out data. As a result, we unintentionally also model the noise or random elements of the training set. If that happens, our model will not generalize well when tested on new inputs. <br />\n",
    "There are generally two main approaches to addressing the overfitting problem.\n",
    "* Stop the training process early\n",
    "* Regularization <br />\n",
    "\n",
    "When we stop the training process early, we do that in the region where the network begins to overfit. By doing so, we reduce degradation in the performance on the test set. It would be ideal if we knew precisely when we should stop the training process, however, that is often difficult to determine. One way of determining when to stop the training is by carving a small dataset out of the training set which we will call the _**validation set**_ Assuming that the accuracy of the validation set is similar to that of the test set, we can use it to estimate when the training should stop. The drawback of this approach is that we end up with fewer samples to train our model on, so our training set is smaller. <br />\n",
    "And alternative mainstream approach to mitigating overfitting is to use _**regularization**_. Regularization means that we impose a constraint on the training of the network such that better generalization can be achieved._**Dropout**_ is a widely used regularization scheme which helps in that manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
